{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b604a54",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdcd38ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier  # o altri\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944870e1",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f9b45f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82486, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>subject_len</th>\n",
       "      <th>body_len</th>\n",
       "      <th>subject_density</th>\n",
       "      <th>body_density</th>\n",
       "      <th>num_exclamations</th>\n",
       "      <th>body_entropy</th>\n",
       "      <th>body_entropy_per_char</th>\n",
       "      <th>percent_digits</th>\n",
       "      <th>percent_punct</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Re: New Sequences Window</td>\n",
       "      <td>Date:        Wed, 21 Aug 2002 10:54:46 -0500  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>24</td>\n",
       "      <td>1538</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>6.835556</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9731</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>0.0670</td>\n",
       "      <td>0.1268</td>\n",
       "      <td>Re: New Sequences Window Date:        Wed, 21 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[zzzzteana] RE: Alexander</td>\n",
       "      <td>Martin A posted:\\nTassos Papadopoulos, the Gre...</td>\n",
       "      <td>0</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>25</td>\n",
       "      <td>894</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>7.982143</td>\n",
       "      <td>2</td>\n",
       "      <td>4.6876</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>[zzzzteana] RE: Alexander Martin A posted:\\nTa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[zzzzteana] Moscow bomber</td>\n",
       "      <td>Man Threatens Explosion In Moscow \\n\\nThursday...</td>\n",
       "      <td>0</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>25</td>\n",
       "      <td>1746</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>6.901186</td>\n",
       "      <td>2</td>\n",
       "      <td>4.7850</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.1042</td>\n",
       "      <td>[zzzzteana] Moscow bomber Man Threatens Explos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[IRR] Klez: The Virus That  Won't Die</td>\n",
       "      <td>Klez: The Virus That Won't Die\\n \\nAlready the...</td>\n",
       "      <td>0</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>37</td>\n",
       "      <td>1125</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>6.818182</td>\n",
       "      <td>0</td>\n",
       "      <td>4.7567</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.0818</td>\n",
       "      <td>[IRR] Klez: The Virus That  Won't Die Klez: Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Re: [zzzzteana] Nothing like mama used to make</td>\n",
       "      <td>&gt;  in adding cream to spaghetti carbonara, whi...</td>\n",
       "      <td>0</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>46</td>\n",
       "      <td>1047</td>\n",
       "      <td>5.111111</td>\n",
       "      <td>7.270833</td>\n",
       "      <td>2</td>\n",
       "      <td>4.7307</td>\n",
       "      <td>0.004518</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.1691</td>\n",
       "      <td>Re: [zzzzteana] Nothing like mama used to make...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          subject  \\\n",
       "0                        Re: New Sequences Window   \n",
       "1                       [zzzzteana] RE: Alexander   \n",
       "2                       [zzzzteana] Moscow bomber   \n",
       "3           [IRR] Klez: The Virus That  Won't Die   \n",
       "4  Re: [zzzzteana] Nothing like mama used to make   \n",
       "\n",
       "                                                body  label    source  \\\n",
       "0  Date:        Wed, 21 Aug 2002 10:54:46 -0500  ...      0  Assassin   \n",
       "1  Martin A posted:\\nTassos Papadopoulos, the Gre...      0  Assassin   \n",
       "2  Man Threatens Explosion In Moscow \\n\\nThursday...      0  Assassin   \n",
       "3  Klez: The Virus That Won't Die\\n \\nAlready the...      0  Assassin   \n",
       "4  >  in adding cream to spaghetti carbonara, whi...      0  Assassin   \n",
       "\n",
       "   subject_len  body_len  subject_density  body_density  num_exclamations  \\\n",
       "0           24      1538         4.800000      6.835556                 0   \n",
       "1           25       894         6.250000      7.982143                 2   \n",
       "2           25      1746         6.250000      6.901186                 2   \n",
       "3           37      1125         4.625000      6.818182                 0   \n",
       "4           46      1047         5.111111      7.270833                 2   \n",
       "\n",
       "   body_entropy  body_entropy_per_char  percent_digits  percent_punct  \\\n",
       "0        4.9731               0.003233          0.0670         0.1268   \n",
       "1        4.6876               0.005243          0.0134         0.2069   \n",
       "2        4.7850               0.002741          0.0074         0.1042   \n",
       "3        4.7567               0.004228          0.0240         0.0818   \n",
       "4        4.7307               0.004518          0.0038         0.1691   \n",
       "\n",
       "                                                text  \n",
       "0  Re: New Sequences Window Date:        Wed, 21 ...  \n",
       "1  [zzzzteana] RE: Alexander Martin A posted:\\nTa...  \n",
       "2  [zzzzteana] Moscow bomber Man Threatens Explos...  \n",
       "3  [IRR] Klez: The Virus That  Won't Die Klez: Th...  \n",
       "4  Re: [zzzzteana] Nothing like mama used to make...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dataset/3_features_phishing_enhanced.csv\")\n",
    "print(df.shape)\n",
    "df = df.drop(columns=['num_links', 'num_special_chars', 'has_bank_word'])\n",
    "df_filtered = df[df['source'] != 'Nazario'] # provo a togliere Nazario\n",
    "df = df_filtered\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b944472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ling', 'Enron', 'CEAS-08', 'Nigerian_Fraud', 'Assassin'}\n"
     ]
    }
   ],
   "source": [
    "print(set(df['source'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e0930e",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9204e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ff32f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      7919\n",
      "           1       0.98      0.98      0.98      8579\n",
      "\n",
      "    accuracy                           0.98     16498\n",
      "   macro avg       0.98      0.98      0.98     16498\n",
      "weighted avg       0.98      0.98      0.98     16498\n",
      "\n",
      "[[7789  130]\n",
      " [ 134 8445]]\n"
     ]
    }
   ],
   "source": [
    "# text_col = ['text']  # body, subject, text (subject + body)\n",
    "num_cols = [\n",
    "    'subject_len', 'body_len', 'subject_density', 'body_density','num_links', 'num_special_chars',\n",
    "    'num_exclamations', 'body_entropy', 'body_entropy_per_char', 'percent_digits','has_bank_word', 'percent_punct'\n",
    "]\n",
    "\n",
    "text_col = 'text'\n",
    "\n",
    "# Split\n",
    "X = df[[text_col]+ num_cols]\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing: text + numeriche\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2)), text_col),\n",
    "    ('num', StandardScaler(), num_cols)\n",
    "])\n",
    "\n",
    "# Modello di partenza (cambia qui con altri modelli)\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('clf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Addestramento\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Valutazione\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# ottengo valori alti, il modello generalizza troppo forse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aaf991",
   "metadata": {},
   "source": [
    "### Leave-one-out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa74853a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Valutazione su sorgente esclusa: Assassin\n",
      "\n",
      "🔍 Valutazione su sorgente esclusa: CEAS-08\n",
      "\n",
      "🔍 Valutazione su sorgente esclusa: Nigerian_Fraud\n",
      "\n",
      "🔍 Valutazione su sorgente esclusa: Nazario\n",
      "\n",
      "🔍 Valutazione su sorgente esclusa: Enron\n",
      "\n",
      "🔍 Valutazione su sorgente esclusa: Ling\n",
      "\n",
      "📊 Risultati Leave-One-Source-Out:\n",
      "\n",
      "                support  accuracy  precision  recall  f1-score\n",
      "Assassin         5809.0     0.878      0.801   0.782     0.792\n",
      "CEAS-08         39154.0     0.851      0.886   0.841     0.863\n",
      "Nigerian_Fraud   3332.0     0.957      1.000   0.957     0.978\n",
      "Nazario          1565.0     0.668      1.000   0.668     0.801\n",
      "Enron           29767.0     0.781      0.744   0.816     0.778\n",
      "Ling             2859.0     0.942      0.798   0.856     0.826\n"
     ]
    }
   ],
   "source": [
    "text_col = 'text'\n",
    "num_cols = [\n",
    "    'subject_len', 'body_len', 'subject_density', 'body_density',\n",
    "    'num_links', 'num_special_chars', 'num_exclamations',\n",
    "    'body_entropy', 'body_entropy_per_char', 'percent_digits',\n",
    "    'has_bank_word', 'percent_punct'\n",
    "]\n",
    "\n",
    "# Output complessivo\n",
    "results = {}\n",
    "\n",
    "# Loop Leave-One-Source-Out\n",
    "for source_name in df['source'].unique():\n",
    "    print(f\"\\n🔍 Valutazione su sorgente esclusa: {source_name}\")\n",
    "    \n",
    "    train = df[df['source'] != source_name]\n",
    "    test = df[df['source'] == source_name]\n",
    "\n",
    "    # Features e label\n",
    "    X_train = train[[text_col] + num_cols]\n",
    "    y_train = train['label']\n",
    "    X_test = test[[text_col] + num_cols]\n",
    "    y_test = test['label']\n",
    "\n",
    "    # Pipeline\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2)), text_col),\n",
    "        ('num', StandardScaler(), num_cols)\n",
    "    ])\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('clf', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Train\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Test\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "    \n",
    "    results[source_name] = {\n",
    "        'support': len(y_test),\n",
    "        'accuracy': (y_pred == y_test).mean(),\n",
    "        'precision': report['1']['precision'],\n",
    "        'recall': report['1']['recall'],\n",
    "        'f1-score': report['1']['f1-score']\n",
    "    }\n",
    "\n",
    "# Output riepilogativo\n",
    "df_results = pd.DataFrame(results).T\n",
    "print(\"\\n📊 Risultati Leave-One-Source-Out:\\n\")\n",
    "print(df_results.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e7fd540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio su file\n",
    "import pickle \n",
    "\n",
    "with open(\"dati.pkl\", \"wb\") as file:  # \"wb\" significa scrittura in modalità binaria\n",
    "    pickle.dump(df_results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8008edf1",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74623abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Validazione su: Assassin\n",
      "\n",
      "🔍 Validazione su: CEAS-08\n",
      "\n",
      "🔍 Validazione su: Nigerian_Fraud\n",
      "\n",
      "🔍 Validazione su: Enron\n",
      "\n",
      "🔍 Validazione su: Ling\n",
      "\n",
      "📊 Risultati LOSO:\n",
      "                 support  accuracy  precision  recall  f1-score\n",
      "Assassin         5809.0     0.865      0.799   0.724     0.760\n",
      "CEAS-08         39154.0     0.851      0.884   0.843     0.863\n",
      "Nigerian_Fraud   3332.0     0.964      1.000   0.964     0.982\n",
      "Enron           29767.0     0.819      0.777   0.862     0.817\n",
      "Ling             2859.0     0.917      0.671   0.943     0.784\n"
     ]
    }
   ],
   "source": [
    "text_col = 'text'\n",
    "num_cols = [\n",
    "    'subject_len', 'body_len', 'subject_density', 'body_density',\n",
    "    'num_exclamations', 'percent_punct',\n",
    "    'body_entropy', 'body_entropy_per_char', 'percent_digits',\n",
    "    #'has_bank_word', 'num_links',  'num_special_chars'\n",
    "]\n",
    "\n",
    "# Preprocessing da riutilizzare\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('tfidf', TfidfVectorizer(max_features=10000, ngram_range=(1, 3),  min_df=5, max_df=0.8), text_col),\n",
    "    ('num', StandardScaler(), num_cols)\n",
    "])\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Leave-One-Source-Out Evaluation\n",
    "for source_name in df['source'].unique():\n",
    "    print(f\"\\n🔍 Validazione su: {source_name}\")\n",
    "    \n",
    "    train = df[df['source'] != source_name]\n",
    "    test = df[df['source'] == source_name]\n",
    "\n",
    "    X_train = train[[text_col] + num_cols]\n",
    "    y_train = train['label']\n",
    "    X_test = test[[text_col] + num_cols]\n",
    "    y_test = test['label']\n",
    "    neg, pos = np.bincount(y_train)\n",
    "    scale = neg / pos\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('clf', XGBClassifier(eval_metric='logloss', scale_pos_weight=scale))\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "    results[source_name] = {\n",
    "        'support': len(y_test),\n",
    "        'accuracy': (y_pred == y_test).mean(),\n",
    "        'precision': report['1']['precision'],\n",
    "        'recall': report['1']['recall'],\n",
    "        'f1-score': report['1']['f1-score']\n",
    "    }\n",
    "\n",
    "df_results = pd.DataFrame(results).T\n",
    "print(\"\\n📊 Risultati LOSO:\\n\", df_results.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd28a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_col = 'text'\n",
    "num_cols = [\n",
    "    'subject_len', 'body_len', 'subject_density', 'body_density',\n",
    "    'num_exclamations', 'percent_punct',\n",
    "    'body_entropy', 'body_entropy_per_char', 'percent_digits',\n",
    "    #'has_bank_word', 'num_links',  'num_special_chars'\n",
    "]\n",
    "\n",
    "text_col = 'text'\n",
    "\n",
    "# Preprocessing da riutilizzare\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('tfidf', TfidfVectorizer(max_features=10000, ngram_range=(1, 3),  min_df=5, max_df=0.8), text_col),\n",
    "    ('num', StandardScaler(), num_cols)\n",
    "])\n",
    "\n",
    "# Split\n",
    "X = df[[text_col]+ num_cols]\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Modello di partenza (cambia qui con altri modelli)\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('clf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Addestramento\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# ottengo valori alti, il modello generalizza troppo forse.\n",
    "\n",
    "results = {}\n",
    "\n",
    "results['all'] = {\n",
    "        'support': len(y_test),\n",
    "        'accuracy': (y_pred == y_test).mean(),\n",
    "        'precision': report['1']['precision'],\n",
    "        'recall': report['1']['recall'],\n",
    "        'f1-score': report['1']['f1-score']\n",
    "}\n",
    "\n",
    "df_results = pd.DataFrame(results).T\n",
    "print(\"\\n📊 Risultati:\\n\", df_results.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08655212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final training on full dataset\n",
    "X_final = df[[text_col] + num_cols]\n",
    "y_final = df['label']\n",
    "\n",
    "final_pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('clf', XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "final_pipeline.fit(X_final, y_final)\n",
    "\n",
    "joblib.dump(final_pipeline, 'phishing_model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4915ae8",
   "metadata": {},
   "source": [
    "## ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0415a55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Validazione su: Assassin\n",
      "\n",
      "🔍 Validazione su: CEAS-08\n",
      "\n",
      "🔍 Validazione su: Nigerian_Fraud\n",
      "\n",
      "🔍 Validazione su: Nazario\n",
      "\n",
      "🔍 Validazione su: Enron\n",
      "\n",
      "🔍 Validazione su: Ling\n",
      "\n",
      "📊 Risultati LOSO:\n",
      "                 support  accuracy  precision  recall  f1-score\n",
      "Assassin         5809.0     0.764      0.562   0.919     0.697\n",
      "CEAS-08         39154.0     0.646      0.837   0.454     0.589\n",
      "Nigerian_Fraud   3332.0     0.522      1.000   0.522     0.686\n",
      "Nazario          1565.0     0.788      1.000   0.788     0.881\n",
      "Enron           29767.0     0.609      0.553   0.877     0.678\n",
      "Ling             2859.0     0.765      0.395   0.878     0.544\n"
     ]
    }
   ],
   "source": [
    "text_col = 'text'\n",
    "num_cols = [\n",
    "    'subject_len', 'body_len', 'subject_density', 'body_density',\n",
    "    'num_links', 'num_special_chars', 'num_exclamations',\n",
    "    'body_entropy', 'body_entropy_per_char', 'percent_digits',\n",
    "    'has_bank_word', 'percent_punct'\n",
    "]\n",
    "\n",
    "# Preprocessing da riutilizzare\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2), min_df=5, max_df=0.8), text_col),\n",
    "    ('num', StandardScaler(), num_cols)\n",
    "])\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Leave-One-Source-Out Evaluation\n",
    "for source_name in df['source'].unique():\n",
    "    print(f\"\\n🔍 Validazione su: {source_name}\")\n",
    "    \n",
    "    train = df[df['source'] != source_name]\n",
    "    test = df[df['source'] == source_name]\n",
    "\n",
    "    X_train = train[[text_col] + num_cols]\n",
    "    y_train = train['label']\n",
    "    X_test = test[[text_col] + num_cols]\n",
    "    y_test = test['label']\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('clf', ExtraTreesClassifier(n_estimators=100, max_depth=10, random_state=42))\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "    results[source_name] = {\n",
    "        'support': len(y_test),\n",
    "        'accuracy': (y_pred == y_test).mean(),\n",
    "        'precision': report['1']['precision'],\n",
    "        'recall': report['1']['recall'],\n",
    "        'f1-score': report['1']['f1-score']\n",
    "    }\n",
    "\n",
    "df_results = pd.DataFrame(results).T\n",
    "print(\"\\n📊 Risultati LOSO:\\n\", df_results.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847d1f14",
   "metadata": {},
   "source": [
    "## ADB - Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f597d90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Validazione su: Assassin\n",
      "\n",
      "🔍 Validazione su: CEAS-08\n",
      "\n",
      "🔍 Validazione su: Nigerian_Fraud\n",
      "\n",
      "🔍 Validazione su: Nazario\n",
      "\n",
      "🔍 Validazione su: Enron\n",
      "\n",
      "🔍 Validazione su: Ling\n",
      "\n",
      "📊 Risultati LOSO:\n",
      "                 support  accuracy  precision  recall  f1-score\n",
      "Assassin         5809.0     0.777      0.594   0.776     0.673\n",
      "CEAS-08         39154.0     0.718      0.821   0.631     0.714\n",
      "Nigerian_Fraud   3332.0     0.779      1.000   0.779     0.876\n",
      "Nazario          1565.0     0.781      1.000   0.781     0.877\n",
      "Enron           29767.0     0.671      0.599   0.903     0.720\n",
      "Ling             2859.0     0.750      0.375   0.836     0.518\n"
     ]
    }
   ],
   "source": [
    "text_col = 'text'\n",
    "num_cols = [\n",
    "    'subject_len', 'body_len', 'subject_density', 'body_density',\n",
    "    'num_links', 'num_special_chars', 'num_exclamations',\n",
    "    'body_entropy', 'body_entropy_per_char', 'percent_digits',\n",
    "    'has_bank_word', 'percent_punct'\n",
    "]\n",
    "\n",
    "# Preprocessing da riutilizzare\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2), min_df=5, max_df=0.8), text_col),\n",
    "    ('num', StandardScaler(), num_cols)\n",
    "])\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Leave-One-Source-Out Evaluation\n",
    "for source_name in df['source'].unique():\n",
    "    print(f\"\\n🔍 Validazione su: {source_name}\")\n",
    "    \n",
    "    train = df[df['source'] != source_name]\n",
    "    test = df[df['source'] == source_name]\n",
    "\n",
    "    X_train = train[[text_col] + num_cols]\n",
    "    y_train = train['label']\n",
    "    X_test = test[[text_col] + num_cols]\n",
    "    y_test = test['label']\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('clf', AdaBoostClassifier(n_estimators=100, learning_rate=0.5))\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "    results[source_name] = {\n",
    "        'support': len(y_test),\n",
    "        'accuracy': (y_pred == y_test).mean(),\n",
    "        'precision': report['1']['precision'],\n",
    "        'recall': report['1']['recall'],\n",
    "        'f1-score': report['1']['f1-score']\n",
    "    }\n",
    "\n",
    "df_results = pd.DataFrame(results).T\n",
    "print(\"\\n📊 Risultati LOSO:\\n\", df_results.round(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
