{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b604a54",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdcd38ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier  # o altri\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944870e1",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f9b45f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82486, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "      <th>subject_len</th>\n",
       "      <th>body_len</th>\n",
       "      <th>subject_density</th>\n",
       "      <th>body_density</th>\n",
       "      <th>num_exclamations</th>\n",
       "      <th>body_entropy</th>\n",
       "      <th>body_entropy_per_char</th>\n",
       "      <th>percent_digits</th>\n",
       "      <th>percent_punct</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Re: New Sequences Window</td>\n",
       "      <td>Date:        Wed, 21 Aug 2002 10:54:46 -0500  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>24</td>\n",
       "      <td>1538</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>6.835556</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9731</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>0.0670</td>\n",
       "      <td>0.1268</td>\n",
       "      <td>Re: New Sequences Window Date:        Wed, 21 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[zzzzteana] RE: Alexander</td>\n",
       "      <td>Martin A posted:\\nTassos Papadopoulos, the Gre...</td>\n",
       "      <td>0</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>25</td>\n",
       "      <td>894</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>7.982143</td>\n",
       "      <td>2</td>\n",
       "      <td>4.6876</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>[zzzzteana] RE: Alexander Martin A posted:\\nTa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[zzzzteana] Moscow bomber</td>\n",
       "      <td>Man Threatens Explosion In Moscow \\n\\nThursday...</td>\n",
       "      <td>0</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>25</td>\n",
       "      <td>1746</td>\n",
       "      <td>6.250000</td>\n",
       "      <td>6.901186</td>\n",
       "      <td>2</td>\n",
       "      <td>4.7850</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.1042</td>\n",
       "      <td>[zzzzteana] Moscow bomber Man Threatens Explos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[IRR] Klez: The Virus That  Won't Die</td>\n",
       "      <td>Klez: The Virus That Won't Die\\n \\nAlready the...</td>\n",
       "      <td>0</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>37</td>\n",
       "      <td>1125</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>6.818182</td>\n",
       "      <td>0</td>\n",
       "      <td>4.7567</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.0818</td>\n",
       "      <td>[IRR] Klez: The Virus That  Won't Die Klez: Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Re: [zzzzteana] Nothing like mama used to make</td>\n",
       "      <td>&gt;  in adding cream to spaghetti carbonara, whi...</td>\n",
       "      <td>0</td>\n",
       "      <td>Assassin</td>\n",
       "      <td>46</td>\n",
       "      <td>1047</td>\n",
       "      <td>5.111111</td>\n",
       "      <td>7.270833</td>\n",
       "      <td>2</td>\n",
       "      <td>4.7307</td>\n",
       "      <td>0.004518</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.1691</td>\n",
       "      <td>Re: [zzzzteana] Nothing like mama used to make...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          subject  \\\n",
       "0                        Re: New Sequences Window   \n",
       "1                       [zzzzteana] RE: Alexander   \n",
       "2                       [zzzzteana] Moscow bomber   \n",
       "3           [IRR] Klez: The Virus That  Won't Die   \n",
       "4  Re: [zzzzteana] Nothing like mama used to make   \n",
       "\n",
       "                                                body  label    source  \\\n",
       "0  Date:        Wed, 21 Aug 2002 10:54:46 -0500  ...      0  Assassin   \n",
       "1  Martin A posted:\\nTassos Papadopoulos, the Gre...      0  Assassin   \n",
       "2  Man Threatens Explosion In Moscow \\n\\nThursday...      0  Assassin   \n",
       "3  Klez: The Virus That Won't Die\\n \\nAlready the...      0  Assassin   \n",
       "4  >  in adding cream to spaghetti carbonara, whi...      0  Assassin   \n",
       "\n",
       "   subject_len  body_len  subject_density  body_density  num_exclamations  \\\n",
       "0           24      1538         4.800000      6.835556                 0   \n",
       "1           25       894         6.250000      7.982143                 2   \n",
       "2           25      1746         6.250000      6.901186                 2   \n",
       "3           37      1125         4.625000      6.818182                 0   \n",
       "4           46      1047         5.111111      7.270833                 2   \n",
       "\n",
       "   body_entropy  body_entropy_per_char  percent_digits  percent_punct  \\\n",
       "0        4.9731               0.003233          0.0670         0.1268   \n",
       "1        4.6876               0.005243          0.0134         0.2069   \n",
       "2        4.7850               0.002741          0.0074         0.1042   \n",
       "3        4.7567               0.004228          0.0240         0.0818   \n",
       "4        4.7307               0.004518          0.0038         0.1691   \n",
       "\n",
       "                                                text  \n",
       "0  Re: New Sequences Window Date:        Wed, 21 ...  \n",
       "1  [zzzzteana] RE: Alexander Martin A posted:\\nTa...  \n",
       "2  [zzzzteana] Moscow bomber Man Threatens Explos...  \n",
       "3  [IRR] Klez: The Virus That  Won't Die Klez: Th...  \n",
       "4  Re: [zzzzteana] Nothing like mama used to make...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../dataset/3_features_phishing_enhanced.csv\")\n",
    "print(df.shape)\n",
    "df = df.drop(columns=['num_links', 'num_special_chars', 'has_bank_word'])\n",
    "df_filtered = df[df['source'] != 'Nazario'] # provo a togliere Nazario\n",
    "df = df_filtered\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b944472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Ling', 'Enron', 'CEAS-08', 'Nigerian_Fraud', 'Assassin'}\n"
     ]
    }
   ],
   "source": [
    "print(set(df['source'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e0930e",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9204e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ff32f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      7919\n",
      "           1       0.98      0.98      0.98      8579\n",
      "\n",
      "    accuracy                           0.98     16498\n",
      "   macro avg       0.98      0.98      0.98     16498\n",
      "weighted avg       0.98      0.98      0.98     16498\n",
      "\n",
      "[[7789  130]\n",
      " [ 134 8445]]\n"
     ]
    }
   ],
   "source": [
    "# text_col = ['text']  # body, subject, text (subject + body)\n",
    "num_cols = [\n",
    "    'subject_len', 'body_len', 'subject_density', 'body_density','num_links', 'num_special_chars',\n",
    "    'num_exclamations', 'body_entropy', 'body_entropy_per_char', 'percent_digits','has_bank_word', 'percent_punct'\n",
    "]\n",
    "\n",
    "text_col = 'text'\n",
    "\n",
    "# Split\n",
    "X = df[[text_col]+ num_cols]\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing: text + numeriche\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2)), text_col),\n",
    "    ('num', StandardScaler(), num_cols)\n",
    "])\n",
    "\n",
    "# Modello di partenza (cambia qui con altri modelli)\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('clf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Addestramento\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Valutazione\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# ottengo valori alti, il modello generalizza troppo forse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aaf991",
   "metadata": {},
   "source": [
    "### Leave-one-out Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa74853a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Valutazione su sorgente esclusa: Assassin\n",
      "\n",
      "üîç Valutazione su sorgente esclusa: CEAS-08\n",
      "\n",
      "üîç Valutazione su sorgente esclusa: Nigerian_Fraud\n",
      "\n",
      "üîç Valutazione su sorgente esclusa: Nazario\n",
      "\n",
      "üîç Valutazione su sorgente esclusa: Enron\n",
      "\n",
      "üîç Valutazione su sorgente esclusa: Ling\n",
      "\n",
      "üìä Risultati Leave-One-Source-Out:\n",
      "\n",
      "                support  accuracy  precision  recall  f1-score\n",
      "Assassin         5809.0     0.878      0.801   0.782     0.792\n",
      "CEAS-08         39154.0     0.851      0.886   0.841     0.863\n",
      "Nigerian_Fraud   3332.0     0.957      1.000   0.957     0.978\n",
      "Nazario          1565.0     0.668      1.000   0.668     0.801\n",
      "Enron           29767.0     0.781      0.744   0.816     0.778\n",
      "Ling             2859.0     0.942      0.798   0.856     0.826\n"
     ]
    }
   ],
   "source": [
    "text_col = 'text'\n",
    "num_cols = [\n",
    "    'subject_len', 'body_len', 'subject_density', 'body_density',\n",
    "    'num_links', 'num_special_chars', 'num_exclamations',\n",
    "    'body_entropy', 'body_entropy_per_char', 'percent_digits',\n",
    "    'has_bank_word', 'percent_punct'\n",
    "]\n",
    "\n",
    "# Output complessivo\n",
    "results = {}\n",
    "\n",
    "# Loop Leave-One-Source-Out\n",
    "for source_name in df['source'].unique():\n",
    "    print(f\"\\nüîç Valutazione su sorgente esclusa: {source_name}\")\n",
    "    \n",
    "    train = df[df['source'] != source_name]\n",
    "    test = df[df['source'] == source_name]\n",
    "\n",
    "    # Features e label\n",
    "    X_train = train[[text_col] + num_cols]\n",
    "    y_train = train['label']\n",
    "    X_test = test[[text_col] + num_cols]\n",
    "    y_test = test['label']\n",
    "\n",
    "    # Pipeline\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2)), text_col),\n",
    "        ('num', StandardScaler(), num_cols)\n",
    "    ])\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('clf', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "\n",
    "    # Train\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Test\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "    \n",
    "    results[source_name] = {\n",
    "        'support': len(y_test),\n",
    "        'accuracy': (y_pred == y_test).mean(),\n",
    "        'precision': report['1']['precision'],\n",
    "        'recall': report['1']['recall'],\n",
    "        'f1-score': report['1']['f1-score']\n",
    "    }\n",
    "\n",
    "# Output riepilogativo\n",
    "df_results = pd.DataFrame(results).T\n",
    "print(\"\\nüìä Risultati Leave-One-Source-Out:\\n\")\n",
    "print(df_results.round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e7fd540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvataggio su file\n",
    "import pickle \n",
    "\n",
    "with open(\"dati.pkl\", \"wb\") as file:  # \"wb\" significa scrittura in modalit√† binaria\n",
    "    pickle.dump(df_results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8008edf1",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74623abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Validazione su: Assassin\n",
      "\n",
      "üîç Validazione su: CEAS-08\n",
      "\n",
      "üîç Validazione su: Nigerian_Fraud\n",
      "\n",
      "üîç Validazione su: Enron\n",
      "\n",
      "üîç Validazione su: Ling\n",
      "\n",
      "üìä Risultati LOSO:\n",
      "                 support  accuracy  precision  recall  f1-score\n",
      "Assassin         5809.0     0.865      0.799   0.724     0.760\n",
      "CEAS-08         39154.0     0.851      0.884   0.843     0.863\n",
      "Nigerian_Fraud   3332.0     0.964      1.000   0.964     0.982\n",
      "Enron           29767.0     0.819      0.777   0.862     0.817\n",
      "Ling             2859.0     0.917      0.671   0.943     0.784\n"
     ]
    }
   ],
   "source": [
    "text_col = 'text'\n",
    "num_cols = [\n",
    "    'subject_len', 'body_len', 'subject_density', 'body_density',\n",
    "    'num_exclamations', 'percent_punct',\n",
    "    'body_entropy', 'body_entropy_per_char', 'percent_digits',\n",
    "    #'has_bank_word', 'num_links',  'num_special_chars'\n",
    "]\n",
    "\n",
    "# Preprocessing da riutilizzare\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('tfidf', TfidfVectorizer(max_features=10000, ngram_range=(1, 3),  min_df=5, max_df=0.8), text_col),\n",
    "    ('num', StandardScaler(), num_cols)\n",
    "])\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Leave-One-Source-Out Evaluation\n",
    "for source_name in df['source'].unique():\n",
    "    print(f\"\\nüîç Validazione su: {source_name}\")\n",
    "    \n",
    "    train = df[df['source'] != source_name]\n",
    "    test = df[df['source'] == source_name]\n",
    "\n",
    "    X_train = train[[text_col] + num_cols]\n",
    "    y_train = train['label']\n",
    "    X_test = test[[text_col] + num_cols]\n",
    "    y_test = test['label']\n",
    "    neg, pos = np.bincount(y_train)\n",
    "    scale = neg / pos\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('clf', XGBClassifier(eval_metric='logloss', scale_pos_weight=scale))\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "    results[source_name] = {\n",
    "        'support': len(y_test),\n",
    "        'accuracy': (y_pred == y_test).mean(),\n",
    "        'precision': report['1']['precision'],\n",
    "        'recall': report['1']['recall'],\n",
    "        'f1-score': report['1']['f1-score']\n",
    "    }\n",
    "\n",
    "df_results = pd.DataFrame(results).T\n",
    "print(\"\\nüìä Risultati LOSO:\\n\", df_results.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd28a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_col = 'text'\n",
    "num_cols = [\n",
    "    'subject_len', 'body_len', 'subject_density', 'body_density',\n",
    "    'num_exclamations', 'percent_punct',\n",
    "    'body_entropy', 'body_entropy_per_char', 'percent_digits',\n",
    "    #'has_bank_word', 'num_links',  'num_special_chars'\n",
    "]\n",
    "\n",
    "text_col = 'text'\n",
    "\n",
    "# Preprocessing da riutilizzare\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('tfidf', TfidfVectorizer(max_features=10000, ngram_range=(1, 3),  min_df=5, max_df=0.8), text_col),\n",
    "    ('num', StandardScaler(), num_cols)\n",
    "])\n",
    "\n",
    "# Split\n",
    "X = df[[text_col]+ num_cols]\n",
    "y = df['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Modello di partenza (cambia qui con altri modelli)\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('clf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Addestramento\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# ottengo valori alti, il modello generalizza troppo forse.\n",
    "\n",
    "results = {}\n",
    "\n",
    "results['all'] = {\n",
    "        'support': len(y_test),\n",
    "        'accuracy': (y_pred == y_test).mean(),\n",
    "        'precision': report['1']['precision'],\n",
    "        'recall': report['1']['recall'],\n",
    "        'f1-score': report['1']['f1-score']\n",
    "}\n",
    "\n",
    "df_results = pd.DataFrame(results).T\n",
    "print(\"\\nüìä Risultati:\\n\", df_results.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08655212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final training on full dataset\n",
    "X_final = df[[text_col] + num_cols]\n",
    "y_final = df['label']\n",
    "\n",
    "final_pipeline = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('clf', XGBClassifier(use_label_encoder=False, eval_metric='logloss'))\n",
    "])\n",
    "\n",
    "final_pipeline.fit(X_final, y_final)\n",
    "\n",
    "joblib.dump(final_pipeline, 'phishing_model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4915ae8",
   "metadata": {},
   "source": [
    "## ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0415a55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Validazione su: Assassin\n",
      "\n",
      "üîç Validazione su: CEAS-08\n",
      "\n",
      "üîç Validazione su: Nigerian_Fraud\n",
      "\n",
      "üîç Validazione su: Nazario\n",
      "\n",
      "üîç Validazione su: Enron\n",
      "\n",
      "üîç Validazione su: Ling\n",
      "\n",
      "üìä Risultati LOSO:\n",
      "                 support  accuracy  precision  recall  f1-score\n",
      "Assassin         5809.0     0.764      0.562   0.919     0.697\n",
      "CEAS-08         39154.0     0.646      0.837   0.454     0.589\n",
      "Nigerian_Fraud   3332.0     0.522      1.000   0.522     0.686\n",
      "Nazario          1565.0     0.788      1.000   0.788     0.881\n",
      "Enron           29767.0     0.609      0.553   0.877     0.678\n",
      "Ling             2859.0     0.765      0.395   0.878     0.544\n"
     ]
    }
   ],
   "source": [
    "text_col = 'text'\n",
    "num_cols = [\n",
    "    'subject_len', 'body_len', 'subject_density', 'body_density',\n",
    "    'num_links', 'num_special_chars', 'num_exclamations',\n",
    "    'body_entropy', 'body_entropy_per_char', 'percent_digits',\n",
    "    'has_bank_word', 'percent_punct'\n",
    "]\n",
    "\n",
    "# Preprocessing da riutilizzare\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2), min_df=5, max_df=0.8), text_col),\n",
    "    ('num', StandardScaler(), num_cols)\n",
    "])\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Leave-One-Source-Out Evaluation\n",
    "for source_name in df['source'].unique():\n",
    "    print(f\"\\nüîç Validazione su: {source_name}\")\n",
    "    \n",
    "    train = df[df['source'] != source_name]\n",
    "    test = df[df['source'] == source_name]\n",
    "\n",
    "    X_train = train[[text_col] + num_cols]\n",
    "    y_train = train['label']\n",
    "    X_test = test[[text_col] + num_cols]\n",
    "    y_test = test['label']\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('clf', ExtraTreesClassifier(n_estimators=100, max_depth=10, random_state=42))\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "    results[source_name] = {\n",
    "        'support': len(y_test),\n",
    "        'accuracy': (y_pred == y_test).mean(),\n",
    "        'precision': report['1']['precision'],\n",
    "        'recall': report['1']['recall'],\n",
    "        'f1-score': report['1']['f1-score']\n",
    "    }\n",
    "\n",
    "df_results = pd.DataFrame(results).T\n",
    "print(\"\\nüìä Risultati LOSO:\\n\", df_results.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847d1f14",
   "metadata": {},
   "source": [
    "## ADB - Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f597d90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Validazione su: Assassin\n",
      "\n",
      "üîç Validazione su: CEAS-08\n",
      "\n",
      "üîç Validazione su: Nigerian_Fraud\n",
      "\n",
      "üîç Validazione su: Nazario\n",
      "\n",
      "üîç Validazione su: Enron\n",
      "\n",
      "üîç Validazione su: Ling\n",
      "\n",
      "üìä Risultati LOSO:\n",
      "                 support  accuracy  precision  recall  f1-score\n",
      "Assassin         5809.0     0.777      0.594   0.776     0.673\n",
      "CEAS-08         39154.0     0.718      0.821   0.631     0.714\n",
      "Nigerian_Fraud   3332.0     0.779      1.000   0.779     0.876\n",
      "Nazario          1565.0     0.781      1.000   0.781     0.877\n",
      "Enron           29767.0     0.671      0.599   0.903     0.720\n",
      "Ling             2859.0     0.750      0.375   0.836     0.518\n"
     ]
    }
   ],
   "source": [
    "text_col = 'text'\n",
    "num_cols = [\n",
    "    'subject_len', 'body_len', 'subject_density', 'body_density',\n",
    "    'num_links', 'num_special_chars', 'num_exclamations',\n",
    "    'body_entropy', 'body_entropy_per_char', 'percent_digits',\n",
    "    'has_bank_word', 'percent_punct'\n",
    "]\n",
    "\n",
    "# Preprocessing da riutilizzare\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('tfidf', TfidfVectorizer(max_features=5000, ngram_range=(1, 2), min_df=5, max_df=0.8), text_col),\n",
    "    ('num', StandardScaler(), num_cols)\n",
    "])\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Leave-One-Source-Out Evaluation\n",
    "for source_name in df['source'].unique():\n",
    "    print(f\"\\nüîç Validazione su: {source_name}\")\n",
    "    \n",
    "    train = df[df['source'] != source_name]\n",
    "    test = df[df['source'] == source_name]\n",
    "\n",
    "    X_train = train[[text_col] + num_cols]\n",
    "    y_train = train['label']\n",
    "    X_test = test[[text_col] + num_cols]\n",
    "    y_test = test['label']\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('clf', AdaBoostClassifier(n_estimators=100, learning_rate=0.5))\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "    results[source_name] = {\n",
    "        'support': len(y_test),\n",
    "        'accuracy': (y_pred == y_test).mean(),\n",
    "        'precision': report['1']['precision'],\n",
    "        'recall': report['1']['recall'],\n",
    "        'f1-score': report['1']['f1-score']\n",
    "    }\n",
    "\n",
    "df_results = pd.DataFrame(results).T\n",
    "print(\"\\nüìä Risultati LOSO:\\n\", df_results.round(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
